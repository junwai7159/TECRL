import torch
import numpy as np
import logging
from utils.utils import xy2rscnt, mod2pi, rotate, get_ttcmd


class Pedsim:
    """
    simulation environment
    """
    def __init__(self, args, dt=0.08):
        """
        - args: return value of utils.utils.get_args()
        - dt: simulation time step
        """
        self.meta_data = {'time_unit': dt}

        self.num_pedestrians = 0  # N
        self.num_steps = 0  # T
        self.num_obstacles = 0 # M

        self.args = args
        self.device = args.DEVICE
        self.position = None  # (N, T, 2), pedestrians' positions
        self.velocity = None  # (N, T, 2), pedestrians' velocities
        self.raw_velocity = None  # (N, T, 2), the velocities generated by agents, regardless the deceleration caused by collisions
        self.direction = None  # (N, T, 1), pedestrians' orientations, in rad unit
        self.destination = None  # (N, 2), pedestrians' destinations
        self.obstacle = None  # (M, 2), obstacles' positions
        self.arrive_flag = None  # (N, T), bool, whether pedestrians arrive their destinations
        self.mask = None  # (N, T), bool, whether pedestrians exist in the environment

        self.ped_radius = 0.3
        self.obstacle_radius = 0.1
        self.pref_speed = 1.33
        self.max_speed = 2.5

    def add_obstacle(self, obstacle, init=False):
        """
        给定障碍物的位置, 将其添加到场景中. 
        :param obstacle: dim = [dM, 2]
        :param init: 是否不保留原有的 obstacle
        :return:
        """
        obstacle = obstacle.to(self.device)
        if init or (self.obstacle is None):
            self.obstacle = obstacle
        else:
            self.obstacle = torch.cat([self.obstacle, obstacle], dim=0)
        self.num_obstacles = self.obstacle.shape[0]

    def init_ped(self, position, velocity, destination):
        """
        给定若干行人的信息, 将其添加到场景中. 
        :param position: dim = [N, T, 2]
        :param velocity: dim = [N, T, 2]
        :param destination: dim = [N, 2]
        :return: None
        """
        N, T, _ = position.shape
        assert position.shape == torch.Size([N, T, 2]), "position 维度错误! "
        assert velocity.shape == torch.Size([N, T, 2]), "velocity 维度错误! "
        assert destination.shape == torch.Size([N, 2]), "destination 维度错误! "

        position_ = position.to(self.device)
        velocity_ = velocity.to(self.device)
        mask_ = ~(position_.isnan().any(dim=-1) | velocity_.isnan().any(dim=-1))  # (N, T), 若 position 或 velocity 为 nan, 则设置对应人在对应时刻的 mask 为 False
        position_[~mask_, :] = float('nan')
        velocity_[~mask_, :] = float('nan')

        direction_ = torch.atan2(velocity_[:, :, (1,)], velocity_[:, :, (0,)])
        destination_ = destination.to(self.device)
        arrive_flag_ = ((position_ - destination_[:, None, :]).norm(dim=-1) < self.ped_radius)  # (N, T)

        self.num_steps = T
        self.num_pedestrians = N
        self.position = position_
        self.velocity = velocity_
        self.direction = direction_
        self.destination = destination_
        self.arrive_flag = arrive_flag_
        self.mask = mask_
        self.raw_velocity = velocity_
        # logging.debug(f"初始化场景完成, 当前场景中共 {self.num_pedestrians} 个行人, {self.num_steps} 时间步. ")

    def load_ped(self, position):
        """
        给定若干行人的位置, 解析计算对应的速度和目的地, 并以此初始化自身
        """
        N, T, _ = position.shape
        dt = self.meta_data['time_unit']
        mask = ~position.isnan().any(dim=-1)
        into_flag = mask.clone(); into_flag[:, 1:] &= ~mask[:, :-1]
        exit_flag = mask.clone(); exit_flag[:, :-1] &= ~mask[:, 1:]
        assert (into_flag.sum(dim=1) == 1).all(), "所有人必须进入场景一次! " 
        assert (exit_flag.sum(dim=1) == 1).all(), "所有人必须离开场景一次! " 
        into_time = into_flag.nonzero()[:, 1]  # (N,), 所有人的最初出现时间
        exit_time = exit_flag.nonzero()[:, 1]  # (N,), 所有人的最后出现时间
        velocity = position.diff(dim=1, prepend=position[:, (0,)]) / dt
        velocity[into_flag, :] = velocity.roll(shifts=-1, dims=1)[into_flag, :]
        # assert (into_time < exit_time).all(), "有人在场景中只待了一帧! 速度不好处理"
        velocity[into_flag] = velocity[into_flag].masked_fill((into_time == exit_time).unsqueeze(-1), 0.)  # 只在场景中待了一步的人 (包括最后一步才入场的人), roll 无法为速度赋予合适的值, 因此手动设成 0., 但其实设成什么都不影响
        assert velocity[mask, :].isnan().logical_not().all(), "?"
        destination = position[exit_flag, :]  # (N, 2)
        self.init_ped(position, velocity, destination)

    def add_pedestrian(self, position, velocity, destination, init=False):
        """
        给定一个 (若干) 行人的位置, 速度, 目的地, 半径, 将其添加到场景中. 
        :param position: dim = [n, 2]
        :param velocity: dim = [n, 2]
        :param destination: dim = [n, 2]
        :param init: 是否不保留原有行人
        :return: None
        """
        n = position.shape[0]
        assert velocity.shape[0] == n, "velocity 维度错误! "
        assert destination.shape[0] == n, "destination 维度错误! "

        if init:
            self.num_steps = 1
            self.position = position.view(-1, 1, 2).to(self.device)
            self.velocity = velocity.view(-1, 1, 2).to(self.device)
            self.direction = torch.atan2(velocity[:, 1], velocity[:, 0]).view(-1, 1, 1).to(self.device)
            self.destination = destination.to(self.device)
            self.arrive_flag = torch.full((n, 1), False, device=self.device)
            self.num_pedestrians = n
            mask = ~(position.isnan().any(dim=-1) | velocity.isnan().any(dim=-1))
            self.mask = mask.view(-1, 1).to(device=self.device)
            self.raw_velocity = self.velocity
        else:
            raise NotImplementedError
            position_ = float('nan') + torch.zeros((n, self.num_steps or 1, 2))
            position_[:, -1, :] = position
            velocity_ = float('nan') + torch.zeros((n, self.num_steps or 1, 2))
            velocity_[:, -1, :] = velocity
            arrive_flag_ = float('nan') + torch.zeros((n, self.num_steps or 1, 1))
            arrive_flag_[:, -1, :] = 0

            self.position = torch.cat([self.position, position_.to(self.device)], dim=0)
            self.velocity = torch.cat([self.velocity, velocity_.to(self.device)], dim=0)
            self.destination = torch.cat([self.destination, destination.to(self.device)], dim=0)
            self.arrive_flag = torch.cat([self.arrive_flag, arrive_flag_.to(self.device)], dim=0)
            self.num_pedestrians += n

        # logging.debug(f"添加了 {n} 个行人, 场景中共 {self.num_pedestrians} 个行人. ")

    def add_step(self, position, velocity, init=False):
        """
        给定一个 (若干) 行人的位置, 速度, 将其添加为新的一步. 与 self.action 有相同的效果. 
        若 position 或 velocity 为 nan 则将 position 和 velocity 置为 nan, 并记 mask 为 False
        :param position: dim = [N, 2]
        :param velocity: dim = [N, 2]
        :param destination: dim = [N, 2]
        :return: None
        """
        N = position.shape[0]
        assert velocity.shape[0] == N, "velocity 维度错误! "

        mask = position.isnan().any(dim=-1) + velocity.isnan().any(dim=-1)
        position[mask, :] = float('nan')
        velocity[mask, :] = float('nan')

        if init:
            self.num_pedestrians = N
            self.num_steps = 1
            self.position = position.view(N, 1, 2).to(self.device)
            self.velocity = velocity.view(N, 1, 2).to(self.device)
            self.direction = torch.atan2(velocity[:, 1], velocity[:, 0]).view(N, 1, 1).to(self.device)
            self.mask = ~mask.view(N, 1).to(self.device)
            self.arrive_flag = torch.full((N, 1), False).to(self.device)
            self.raw_velocity = self.velocity
        else:
            assert self.num_pedestrians == N, "position 维度错误! "
            self.num_steps += 1
            self.position = torch.cat([self.position, position.view(N, 1, 2).to(self.device)], dim=1)
            self.velocity = torch.cat([self.velocity, velocity.view(N, 1, 2).to(self.device)], dim=1)
            direction = torch.atan2(velocity[:, 1], velocity[:, 0]).view(N, 1, 1).to(self.device)
            self.direction = torch.cat([self.direction, direction], dim=1)
            self.mask = torch.cat([self.mask, ~mask.view(N, 1).to(self.device)], dim=1)
            self.arrive_flag = torch.cat([self.arrive_flag, torch.fall((N, 1), False).to(self.device)], dim=1)
            self.raw_velocity = torch.cat([self.raw_velocity, velocity.view(N, 1, 2).to(self.device)], dim=1)


        # logging.debug(f"添加了 {1} 步, 场景中共 {self.num_steps} 个时间步. ")

    def remove_pedestrian(self, idx):
        """
        指定若干行人, 将其从场景中移除
        :param idx: 布尔数组, True 表示删除, dim = [N]
        :return:
        """
        assert idx.shape[0] == self.num_pedestrians, "id 维度错误! "
        not_idx = torch.logical_not(idx)
        
        self.position = self.position[not_idx]
        self.velocity = self.velocity[not_idx]
        self.raw_velocity = self.raw_velocity[not_idx]
        self.direction = self.direction[not_idx]
        self.destination = self.destination[not_idx]
        self.mask = self.mask[not_idx]
        self.arrive_flag = self.arrive_flag[not_idx]
        self.num_pedestrians -= torch.sum(idx)

        logging.debug(f"删除了 {torch.sum(idx)} 个行人, 场景中共 {self.num_pedestrians} 个行人. ")

    @staticmethod
    def collision(position, obstacle, sum_radius):
        """
        判断 position 中的元素是否与 obstacle 中的元素发生碰撞
        :param position: dim = [N, 2]
        :param obstacle: dim = [inv_mat, 2]
        :param sum_radius: dim = [N, inv_mat]
        :return: 布尔碰撞标记, dim = [N, inv_mat]
        """
        r_po = obstacle.view(1, -1, 2) - position.view(-1, 1, 2)
        d_po = torch.norm(r_po, dim=-1)
        collision = d_po < sum_radius
        return collision

    def reward(self, index=-1):
        reward = dict()
        reward['ARRIVE'] = {'SCALE': self.args.RW_ARRIVE, 'VALUE': self.arrive_flag[:, -1].float()}

        # Energy Consumption
        mass = 60
        dt = self.meta_data['time_unit']
        v = self.raw_velocity[:, index, :].norm(dim=-1)
        w = mod2pi(self.direction[:, index, 0] - self.direction[:, index - 1, 0]) / dt
        energy = mass * (2.23 + 1.26 * v ** 2 + 1. * (.5 * self.ped_radius ** 2) * w ** 2) * dt
        reward['ENERGY'] = {'SCALE': self.args.RW_ENERGY, 'VALUE': energy}
        # logging.debug(f"耗能: {energy}")

        # Process Work
        delt_vel = self.raw_velocity[:, index, :] - self.velocity[:, index - 1, :]
        work = .5 * mass * (delt_vel * self.velocity[:, index - 1, :]).sum(dim=-1).abs() + .5 * mass * (delt_vel * self.raw_velocity[:, index, :]).sum(dim=-1).abs()
        coll_flag = self.velocity[:, index, :].norm(dim=-1) < self.raw_velocity[:, index, :].norm(dim=-1)
        coll_work = .5 * mass * self.raw_velocity[:, index, :].square().sum(dim=-1)
        work += coll_work.masked_fill_(~coll_flag, 0.)
        reward['WORK'] = {'SCALE': self.args.RW_WORK, 'VALUE': work}
        # logging.debug(f"做功: {work}")
        
        # Mental Effort
        vec2des = self.destination - self.position[:, index - 1, :]  # (N, 2)
        ang2des = torch.cos(mod2pi(torch.atan2(vec2des[:, 1], vec2des[:, 0]) - self.direction[:, index, 0])) # (N,)
        speed = self.velocity[:, index, :].norm(dim=-1)  # (N,)
        mental = ang2des * speed * dt  # (N,)
        reward['MENTAL'] = {'SCALE': self.args.RW_MENTAL, 'VALUE': mental}

        # # CS-DRL
        # delta_l = (self.destination - self.position[:, index - 1, :]).norm(dim=-1) - (self.destination - self.position[:, index, :]).norm(dim=-1)
        # reward['GOAL'] = {'SCALE': 4.0, 'VALUE': delta_l}

        # coll_ped = (self.position[:, None, index, :] - self.position[None, :, index, :]).norm(dim=-1) < (self.ped_radius + self.ped_radius)
        # torch.diagonal(coll_ped)[:] = False
        # coll_obs = (self.position[:, None, index, :] - self.obstacle[None, :, :]).norm(dim=-1) < (self.obstacle_radius + self.ped_radius)
        # coll = coll_ped.any(dim=-1) | coll_obs.any(dim=-1)
        # reward['COLL'] = {'SCALE': -3.0, 'VALUE': coll.float()}

        # v = self.velocity[:, index, :].norm(dim=-1)
        # w = mod2pi(self.direction[:, index, 0] - self.direction[:, index - 1, 0]) # / self.meta_data['time_unit']
        # reward['SMOOTH_V'] = {'SCALE': -4.0, 'VALUE': (v - v.clamp(-0.5, 1.5)).abs()}
        # reward['SMOOTH_W'] = {'SCALE': -1.0, 'VALUE': (w - w.clamp(-np.pi/4, np.pi/4)).abs()}

        # # HOP-RL
        # reward['ARRIVE'] = {'SCALE': 2.0, 'VALUE': self.arrive_flag[:, -1].float()}

        # r_l = (self.destination - self.position[:, index, :]).norm(dim=-1) ** (-.5) - (self.destination - self.position[:, index - 1, :]).norm(dim=-1) ** (-.5)
        
        # md, ttc, msk = get_ttcmd(self, time_range=(index, index + 1))  # (N, N, 1)
        # p_t = ttc.masked_fill_((ttc == 0) & (md > 0), float('inf')).masked_fill_(~msk, float('inf')).tanh().squeeze(-1).prod(dim=-1)
        # reward['GOAL'] = {'SCALE': 3.0, 'VALUE': p_t * r_l}

        # coll_ped = (self.position[:, None, index, :] - self.position[None, :, index, :]).norm(dim=-1) < (self.ped_radius + self.ped_radius)
        # torch.diagonal(coll_ped)[:] = False
        # coll_obs = (self.position[:, None, index, :] - self.obstacle[None, :, :]).norm(dim=-1) < (self.obstacle_radius + self.ped_radius)
        # coll = coll_ped.any(dim=-1) | coll_obs.any(dim=-1)
        # reward['COLL'] = {'SCALE': -0.01, 'VALUE': coll.float()}

        # logging.debug(f"最终 reward: {reward}")

        rwd = torch.zeros([self.num_pedestrians, 1], device=self.device)
        for r in reward.values():
            rwd[:, 0] += r['SCALE'] * r['VALUE']
        return rwd, reward

    def action(self, v, w, enable_nan_action=False):
        """
        给定 velocity = v * exp(j * (w0 + w)), 更新改变场景中行人的位置
        :param v: dim = [N]
        :param w: dim = [N], -pi ~ pi
        :return: reward, dim = [N, 1]
        """
        assert v.shape[0] == self.num_pedestrians, "v 维度错误! "
        assert w.shape[0] == self.num_pedestrians, "w 维度错误! "

        w0 = self.direction[:, -1, 0]
        velocity_ = torch.stack([v * torch.cos(w0 + w), v * torch.sin(w0 + w)], dim=-1)
        direction_ = torch.atan2(velocity_[:, 1], velocity_[:, 0])

        self.raw_velocity = torch.cat([self.raw_velocity, velocity_[:, None, :]], dim=1)
        mask = ~(v.isnan() | w.isnan()).view(-1, 1) if enable_nan_action else self.mask[:, (-1,)]
        self.mask = torch.cat([self.mask, mask], dim=1)

        if not self.args.NO_COLLISION_DETECTION:
            m = self.mask[:, -1]  # N,
            x_ped = self.position[m, -1, :].clone()  # N, 2
            v_ped = velocity_[m, :].clone()  # N, 2
            t_col = torch.full((m.sum(),), self.meta_data['time_unit'], device=self.device)  # (N,), 每个人的碰撞发生的时刻
            x_obs = self.obstacle  # M, 2
            idx_pedped = torch.combinations(torch.arange(x_ped.shape[0]), r=2)  # N(N-1)/2, 2
            if self.obstacle is not None:
                idx_pedobs = torch.stack(torch.meshgrid(torch.arange(x_ped.shape[0]), torch.arange(x_obs.shape[0])), dim=-1).view(-1,2)  # NM, 2
            remaining_t = self.meta_data['time_unit']  # 这一步剩余时间. 每次发生碰撞都会消减之

            while True:
                tau, coll = remaining_t, None  # tau: 最近一次发生碰撞的时间点; coll: 最近一次发生碰撞涉及的行人 (人撞人:[i, j] 人撞墙:[i] 没碰撞:None) 
                
                r_ = 2 * self.ped_radius
                x_corr = torch.nn.functional.pdist(x_ped, p=2)  # size=(N(N-1)/2,), 相当于 (x_ped[idx_pedped[:, 0], :] - x_ped[idx_pedped[:, 1], :]).norm(p=2)
                v_corr = torch.nn.functional.pdist(v_ped, p=2)  # 同上
                filt = (x_corr - v_corr * remaining_t < r_) & (v_corr > 0)  # size=(N(N-1)/2,), 可能发生碰撞的行人对, 初步筛选, 减少后续计算量. 可以用更强的条件, 但大概没必要. v>0 是防止 (v<0)&(x<r) 导致卡死
                if filt.any():
                    x_, v_, idx_ = x_corr[filt], v_corr[filt], idx_pedped[filt, :]  # K,
                    xv_ = ((x_ped[idx_[:, 0], :] - x_ped[idx_[:, 1], :]) * (v_ped[idx_[:, 0], :] - v_ped[idx_[:, 1], :])).sum(dim=-1)  # K,
                    tau_ = - (xv_ + torch.sqrt(xv_**2 - v_**2 * (x_**2 - r_**2))) / (v_**2 + 1e-8)  # K,
                    # tau_ 表示每对人的碰撞时间, 取值 >= dt 表示 dt 时间内不会碰撞. 可以想象成: 一个粒子放在原点静止, 另一个粒子在某个位置以某个速度直线运动, 问何时其运动到原点附近半径为 2R 的圆上
                    # 几种可能的情况: 
                    #   - x_ < r_: 表示已经处于重合状态, 此时有 tau_ < 0. 此时无论如何应当认为未发生碰撞, 否则进入死循环无法解除
                    #   - x_ == r_: 表示恰好处于重合状态, 此时有 tau_ == 0. 建议同上处理
                    #   - v_ == 0: 表示粒子不运动, 不会发生碰撞, 此时有 tau_ == 0 (已重合) 或 nan (未重合)
                    #   - tau_.isnan(): 表示不会碰撞
                    #   - xv_**2 = v_**2 * (x_**2 - r_**2): 表示刚好擦边而过, 建议认为未发生碰撞
                    #   - xv_ > 0: 表示未来不会碰撞, 时间反演才会碰撞, 也等价于 
                    #   - tau_ > 0: 正常的碰撞

                    # if   不靠近   -> inf
                    # elif 不碰撞   -> inf
                    # elif 没不重叠 -> 0
                    # else          -> t
                    tau_.masked_fill_(x_ <= r_, 0.)  # 重叠或恰好重叠 -> 0
                    tau_.masked_fill_((xv_ >= 0) | tau_.isnan(), float('inf'))  # 不靠近或不碰撞 -> inf
                    min_tau_, min_idx_ = torch.min(tau_, dim=0)  # K,
                    if min_tau_ < tau:
                        tau = min_tau_
                        coll = idx_[min_idx_, :]  # 记录发生碰撞的两个人 [i, j]
                        if v_ped[coll[0]].multiply(x_ped[coll[1]] - x_ped[coll[0]]).sum(dim=-1) < 0:  # 0 被追尾, 1 全责
                            coll = coll[1]
                        elif v_ped[coll[1]].multiply(x_ped[coll[0]] - x_ped[coll[1]]).sum(dim=-1) < 0:  # 1 被追尾, 0 全责
                            coll = coll[0]

                if self.obstacle is not None:
                    r_ = self.ped_radius + self.obstacle_radius
                    x_corr = (x_ped.view(-1, 1, 2) - x_obs.view(1, -1, 2)).norm(p=2, dim=-1).view(-1)  # size=(NM,), 相当于 (x_ped[idx_pedobs[:, 0], :] - x_obs[idx_pedobs[:, 1], :]).norm(p=2)
                    v_corr = (v_ped.view(-1, 1, 2)).norm(p=2, dim=-1).repeat(1, x_obs.shape[0]).view(-1)  # 同上
                    xv_corr = ((x_ped.view(-1, 1, 2) - x_obs.view(1, -1, 2)) * (v_ped.view(-1, 1, 2))).sum(dim=-1).view(-1)  # 同上. 
                    filt = (x_corr - v_corr * remaining_t < r_) & (xv_corr < 0) # size=(NM,), 可能发生碰撞的 (行人, 障碍物) 对, 初步筛选, 减少后续计算量. ped-ped 不方便用 xv_corr < 0 的过滤条件, 但 ped-obs 就很方便
                    if filt.any():
                        x_, v_, idx_, xv_ = x_corr[filt], v_corr[filt], idx_pedobs[filt, :], xv_corr[filt]  # K,
                        tau_ = - (xv_ + torch.sqrt(xv_**2 - v_**2 * (x_**2 - r_**2))) / (v_**2 + 1e-8)  # K,
                        tau_.masked_fill_(x_ <= r_, 0.)  # 重叠或恰好重叠 -> 0
                        tau_.masked_fill_((xv_ >= 0) | tau_.isnan(), float('inf'))  # 不靠近或不碰撞 -> inf
                        min_tau_, min_idx_ = torch.min(tau_, dim=0)  # K,
                        if min_tau_ < tau:
                            tau = min_tau_
                            coll = idx_[min_idx_, 0]  # 记录发生碰撞的一个人 [i]
                
                if coll is not None:  # 此时 tau < remaining_t, 即在剩下的 remaining_t 时间内会有碰撞发生
                    t_col[coll] = t_col[coll].clamp_(None, self.meta_data['time_unit'] - remaining_t + tau)  # 更新碰撞时刻, 如果一个人多次发生碰撞, 则只记录第一次碰撞的时刻 (因为最早发生) 
                    x_ped += v_ped * tau  # 更新所有人的位置, 这将导致一个碰撞刚好没发生. 
                    v_ped[coll] = 0.  # 将发生碰撞的人的 v_ped 置零, 表示在剩下 remaining_t 时间内这个人可以看作静止的
                    remaining_t -= tau
                else:  # 剩下的时间里不会有碰撞发生
                    break
            
            velocity_[m, :] *= t_col.unsqueeze(-1) / self.meta_data['time_unit']  # 这里缩小发生碰撞的两个物体的速度, 使得在这一个 step 结束后行人走到的位置刚好是碰撞发生的位置
            
        position_ = self.position[:, -1, :] + velocity_ * self.meta_data['time_unit']
        
        # scale to v_max 
        speed_ = torch.norm(velocity_, dim=-1)  # (N, 1)

        if torch.sum(speed_ > self.max_speed) > 0:    
            scale = self.pref_speed / speed_
            velocity_[speed_ > self.pref_speed, :] *= scale[speed_ > self.pref_speed].unsqueeze(1).repeat(1,2)

        self.velocity = torch.cat([self.velocity, velocity_.view(-1, 1, 2)], dim=1)
        self.direction = torch.cat([self.direction, direction_.view(-1, 1, 1)], dim=1)
        self.position = torch.cat([self.position, position_.view(-1, 1, 2)], dim=1)

        arrive_flag_ = torch.where(self.mask[:, -1], torch.norm(self.position[:, -1, :] - self.destination, dim=-1) < self.ped_radius, self.arrive_flag[:, -1])
        self.arrive_flag = torch.cat([self.arrive_flag, arrive_flag_.view(-1, 1)], dim=1)

        self.num_steps += 1

        # logging.debug(f'添加了一步, 当前时间步为 {self.num_steps}')

        return self.reward()

    def get_state(self, index=-1, include_radius=False, max_obstacles_num=10):
        """
        获取所有行人状态, 使用行人坐标系, 以行人为原点, 方向为极轴 (而非与目的地的连线为极轴) 
        :return:
            s_self: 当前速率 dim = [N, 1]
            s_des: 目的地的相对位置, 方位正余弦, 远离速度, 围绕旋转速度, 当前速率 dim = [N, 8]
            s_ped_obs: 最近若干行人&障碍物的相对位置 (极坐标表示) /速度 (法向切向表示) , dim = [N, 2 * #obstacles, 8]
                5 个特征包括障碍与自己的距离, 障碍相对于自己朝向的方位正余弦, 障碍远离自己的速度, 障碍围绕自己旋转的速度
        """
        s_self = self.velocity[:, index, :].norm(dim=-1, keepdim=True)

        s_des = xy2rscnt(pos=self.destination - self.position[:, index, :], vel=-self.velocity[:, index, :], dir=self.direction[:, index, :])
        
        mask = self.mask[:, index]
        position_ = self.position[mask, index, :]
        velocity_ = self.velocity[mask, index, :]
        direction_ = self.direction[mask, index, :]
        N_ = mask.sum()
        s_ped_ = torch.full((N_, max_obstacles_num, 8), float('nan')).to(self.device)
        s_obs_ = torch.full((N_, max_obstacles_num, 8), float('nan')).to(self.device)
        for p in range(N_):
            pos_ = position_[(p,), :]
            vel_ = velocity_[(p,), :]
            dir_ = direction_[(p,), :]
            pos = torch.cat([position_[:p, :], position_[p + 1:, :]], dim=0)
            vel = torch.cat([velocity_[:p, :], velocity_[p + 1:, :]], dim=0)
            rscnt_ = xy2rscnt(pos=pos - pos_, vel=vel - vel_, dir=dir_)
            rscnt = rscnt_[rscnt_[:, 2] >= 0]  # 只选择能看到的
            if rscnt.shape[0] > max_obstacles_num:  # 能看到的比较多, 只选择最近的 k 个
                _, index = torch.topk(rscnt[:, 0], max_obstacles_num, largest=False)
                rscnt = rscnt[index]
            rscnt[:, 0] = (rscnt[:, 0] - (self.ped_radius if not include_radius else 0.0)).clamp(0.)  # 删去半径
            s_ped_[p, :rscnt.shape[0], :] = rscnt

            if self.obstacle is not None and self.obstacle.numel() > 0:
                rscnt_ = xy2rscnt(pos=self.obstacle - pos_, vel=-vel_, dir=dir_)
                rscnt = rscnt_[rscnt_[:, 2] >= 0]  # 只选择能看到的
                if rscnt.shape[0] > max_obstacles_num:  # 能看到的比较多, 只选择最近的 k 个
                    _, index = torch.topk(rscnt[:, 0], max_obstacles_num, largest=False)
                    rscnt = rscnt[index]
                rscnt[:, 0] = (rscnt[:, 0] - (self.obstacle_radius if not include_radius else 0.)).clamp(0.)  # 删去半径
                s_obs_[p, :rscnt.shape[0], :] = rscnt
        
        s_ped_obs = torch.full((self.num_pedestrians, 2 * max_obstacles_num, 8), float('nan')).to(self.device)
        s_ped_obs[mask, :, :] = torch.cat([s_ped_, s_obs_], dim=1)

        return s_self, s_des, s_ped_obs

    def get_depthmap(self, index=-1, D_MAX=20.0, R_NUM_HALF=10):
        """
        返回 index 时刻 N 个人 观察到的深度图 [N, 2 * R_NUM_HALF + 1]
        """
        depthmap = torch.full_like([self.num_pedestrians, 2 * R_NUM_HALF + 1], float('inf'), device=self.device)

        mask = self.mask[:, index]  # (N,)
        n = mask.sum()
        pos = self.position[mask, index, :]  # (n, 2)
        drc = self.direction[mask, index, 0]  # (n)
        relPos = rotate(pos[None, :, :] - pos[:, None, :], -drc[:, None])  # (n, n, 2) * (n, 1) -> (n, n, 2)
        thetas = torch.linspace(-np.pi, +np.pi, 2 * R_NUM_HALF + 1)
        sd = rotate(relPos.view(1, n, n, 2), thetas.view(-1, 1, 1))  # (R, n, n, 2)
        x = (sd[..., 0] - (self.ped_radius ** 2 - sd[..., 1] ** 2).sqrt())  # (R, n, n)
        x.masked_fill_(sd[..., 0] <= 0. | x.isnan(), float('inf')).clamp_(0.)
        depthmap[mask, :] = torch.min(depthmap[mask, :], x.min(dim=-1).T)  # (n, R) -> (N, R)

        relPos = rotate(self.obstacle[None, :, :] - pos[:, None, :], -drc[:, None])  # (n, M, 2) * (n, 1) -> (n, M, 2)
        thetas = torch.linspace(-np.pi, +np.pi, 2 * R_NUM_HALF + 1)
        sd = rotate(relPos.view(1, n, self.obstacle.shape[0], 2), thetas.view(-1, 1, 1))  # (R, n, M, 2)
        x = sd[..., 0] - (self.obstacle_radius ** 2 - sd[..., 1] ** 2).sqrt()  # (R, n, M)
        x.masked_fill_(sd[..., 0] <= 0. | x.isnan(), float('inf')).clamp_(0.)
        depthmap[mask, :] = torch.min(depthmap[mask, :], x.min(dim=-1).T)  # (n, R) -> (N, R)

        depthmap.masked_fill_(~mask.view(-1, 1), float('nan'))

        return depthmap


    def to(self, device):
        for u, v in self.__dict__.items():
            if type(v) == torch.Tensor:
                exec(f'self.{u} = self.{u}.to(device)')
        return self